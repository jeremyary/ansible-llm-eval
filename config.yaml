
database:
  path: "./results.db"
  clear_on_startup: true

app_settings:
  max_concurrent_llm_calls: 15
  retry_settings:
    max_attempts: 5
    initial_backoff_seconds: 1
    max_backoff_seconds: 60

data_ingestion:
  log_directory: "./ansible_logs"
  enable_chunking: false
  chunk_size: 10000
  chunk_overlap: 500

llm:
  concurrent_requests: 5
  rate_limit_per_minute: 60
  models:
    openai:
      name: "gpt-4.1-2025-04-14"
      parameters:
        temperature: 0.7
      pricing: # USD per 1,000 tokens
        input_per_k_tokens: 0.005
        output_per_k_tokens: 0.015
    gemini:
      name: "gemini-2.5-flash"
      parameters:
        temperature: 0.7
      pricing: # USD per 1,000 tokens
        input_per_k_tokens: 0.007
        output_per_k_tokens: 0.021
    anthropic:
      name: "claude-opus-4-20250514"
      parameters:
        temperature: 0.7
      pricing: # USD per 1,000 tokens
        input_per_k_tokens: 0.003
        output_per_k_tokens: 0.015

prompt_template: |
  You are an expert SRE. Examine the following Ansible log content & summarize in natural language using English. Keep the summary brief, a sentence or two. In your response after the summary, include '[SUGGESTION]' plus one to two sentences summarizing any suggested action to address the error summarized.

  Ansible Log Sample:

  {log_content}

reporting:
  host: "0.0.0.0"
  port: 1111 